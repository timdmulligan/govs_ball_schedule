{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "pd.options.display.float_format = '{:20,.4f}'.format\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in data from the web scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Bring in Data\n",
    "con = sqlite3.connect(\"pitchfork-data.db\")\n",
    "review_data = pd.read_sql_query(\"SELECT * from review_text\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.03038379530912"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data[\"score\"] = review_data[\"score\"].astype(float)\n",
    "review_data[\"score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>author_type</th>\n",
       "      <th>link</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A decade after their last album, Grandaddy pic...</td>\n",
       "      <td>Ian Cohen</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22950-...</td>\n",
       "      <td>Some Grandaddy songs are about technology. Nea...</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The new album from New York’s Immolation is a ...</td>\n",
       "      <td>Saby Reyes-Kulkarni</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22956-...</td>\n",
       "      <td>In the early ’90s, death metal luminaries like...</td>\n",
       "      <td>7.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 20th anniversary remaster of Smith's final...</td>\n",
       "      <td>Matt LeMay</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22947-...</td>\n",
       "      <td>About two minutes into Either/Or opener “Speed...</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yoni Wolf's prog-rap project is rejuvenated, a...</td>\n",
       "      <td>Ian Cohen</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22945-...</td>\n",
       "      <td>The end of WHY? had never been too far from Yo...</td>\n",
       "      <td>7.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Brazilian songwriter Erasmo Carlos remains...</td>\n",
       "      <td>Michael J. Agovino</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22908-...</td>\n",
       "      <td>Over the last half century, few countries have...</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract               author  \\\n",
       "0  A decade after their last album, Grandaddy pic...            Ian Cohen   \n",
       "1  The new album from New York’s Immolation is a ...  Saby Reyes-Kulkarni   \n",
       "2  The 20th anniversary remaster of Smith's final...           Matt LeMay   \n",
       "3  Yoni Wolf's prog-rap project is rejuvenated, a...            Ian Cohen   \n",
       "4  The Brazilian songwriter Erasmo Carlos remains...   Michael J. Agovino   \n",
       "\n",
       "   author_type                                               link  \\\n",
       "0  Contributor  http://www.pitchfork.com/reviews/albums/22950-...   \n",
       "1  Contributor  http://www.pitchfork.com/reviews/albums/22956-...   \n",
       "2  Contributor  http://www.pitchfork.com/reviews/albums/22947-...   \n",
       "3  Contributor  http://www.pitchfork.com/reviews/albums/22945-...   \n",
       "4  Contributor  http://www.pitchfork.com/reviews/albums/22908-...   \n",
       "\n",
       "                                              review                score  \n",
       "0  Some Grandaddy songs are about technology. Nea...               6.0000  \n",
       "1  In the early ’90s, death metal luminaries like...               7.7000  \n",
       "2  About two minutes into Either/Or opener “Speed...              10.0000  \n",
       "3  The end of WHY? had never been too far from Yo...               7.7000  \n",
       "4  Over the last half century, few countries have...               8.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into X and Y and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = review_data[\"review\"]\n",
    "Y = review_data[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# only work with the n most popular words found in our dataset\n",
    "max_words = 5000\n",
    "\n",
    "# create a new Tokenizer and feed reviews to it\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenizers come with a convenient list of words and IDs\n",
    "# Save it so we can reference it later\n",
    "dictionary = tokenizer.word_index\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.preprocessing.text as kpt\n",
    "\n",
    "def convert_text_to_index_array(text):\n",
    "    # one really important thing that `text_to_word_sequence` does\n",
    "    # is make all texts the same length -- in this case, the length\n",
    "    # of the longest text in the set.\n",
    "    return [dictionary[word] for word in kpt.text_to_word_sequence(text)]\n",
    "\n",
    "# for each review, change each token to its ID in the Tokenizer's word_index \n",
    "allWordIndices = []\n",
    "for text in x:\n",
    "    wordIndices = convert_text_to_index_array(text)\n",
    "    allWordIndices.append(wordIndices)\n",
    "\n",
    "# now we have a list of all tweets converted to index arrays.\n",
    "# cast as an array for future usage.\n",
    "allWordIndices = np.asarray(allWordIndices)\n",
    "\n",
    "# create one-hot matrices out of the indexed tweets\n",
    "clean_x = tokenizer.sequences_to_matrix(allWordIndices, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 123\n",
    "X_train, X_test, y_tr_raw, y_te_raw = train_test_split(clean_x, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10692 samples, validate on 3565 samples\n",
      "Epoch 1/5\n",
      "10692/10692 [==============================] - 12s 1ms/step - loss: 1.0989 - mean_absolute_error: 1.0989 - val_loss: 0.7882 - val_mean_absolute_error: 0.7882\n",
      "Epoch 2/5\n",
      "10692/10692 [==============================] - 10s 975us/step - loss: 0.7395 - mean_absolute_error: 0.7395 - val_loss: 0.8111 - val_mean_absolute_error: 0.8111\n",
      "Epoch 3/5\n",
      "10692/10692 [==============================] - 10s 902us/step - loss: 0.6750 - mean_absolute_error: 0.6750 - val_loss: 0.7955 - val_mean_absolute_error: 0.7955\n",
      "Epoch 4/5\n",
      "10692/10692 [==============================] - 10s 919us/step - loss: 0.6238 - mean_absolute_error: 0.6238 - val_loss: 0.8541 - val_mean_absolute_error: 0.8541\n",
      "Epoch 5/5\n",
      "10692/10692 [==============================] - 10s 928us/step - loss: 0.6152 - mean_absolute_error: 0.6152 - val_loss: 0.7636 - val_mean_absolute_error: 0.7636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13579ad50>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def regression_model(activation, kernal):\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(512, activation=activation, kernel_initializer=kernal, input_shape=(max_words,)))\n",
    "    regressor.add(Dense(256, activation=activation, kernel_initializer=kernal))\n",
    "    regressor.add(Dense(12, activation=activation, kernel_initializer=kernal))\n",
    "    regressor.add(Dense(1, activation=activation, kernel_initializer=kernal))\n",
    "    regressor.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])\n",
    "    return regressor\n",
    "\n",
    "regression_model(\"linear\", \"uniform\").fit(X_train, y_tr_raw,\n",
    "  batch_size=32,\n",
    "  epochs=5,\n",
    "  verbose=1,\n",
    "  validation_split=0.25,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scored = regression_model(\"linear\", \"uniform\").predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.034],\n",
       "       [-0.001],\n",
       "       [0.017],\n",
       "       ..., \n",
       "       [0.011],\n",
       "       [0.001],\n",
       "       [0.007]], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0295280350707232"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_te_raw, scored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def myround(x, prec=1, base=.5):\n",
    "    return round(base * round(float(x)/base),prec)\n",
    "\n",
    "#Convert to multi-class dummy variables \n",
    "y_tr, y_te = [myround(x) for x in pd.Series(y_tr_raw)],[myround(x) for x in y_te_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(pd.get_dummies(y_tr))\n",
    "y_test = np.array(pd.get_dummies(y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[0]), len(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(y_train[0]), activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10692 samples, validate on 3565 samples\n",
      "Epoch 1/5\n",
      "10692/10692 [==============================] - 10s 921us/step - loss: 2.2096 - acc: 0.2276 - val_loss: 1.9336 - val_acc: 0.2847\n",
      "Epoch 2/5\n",
      "10692/10692 [==============================] - 9s 811us/step - loss: 1.8135 - acc: 0.3459 - val_loss: 1.8219 - val_acc: 0.3330\n",
      "Epoch 3/5\n",
      "10692/10692 [==============================] - 9s 814us/step - loss: 1.4314 - acc: 0.4980 - val_loss: 1.8024 - val_acc: 0.3599\n",
      "Epoch 4/5\n",
      "10692/10692 [==============================] - 8s 794us/step - loss: 1.0003 - acc: 0.6629 - val_loss: 1.9236 - val_acc: 0.3725\n",
      "Epoch 5/5\n",
      "10692/10692 [==============================] - 9s 876us/step - loss: 0.6236 - acc: 0.8004 - val_loss: 2.1083 - val_acc: 0.3893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2299fd0>"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "  batch_size=32,\n",
    "  epochs=5,\n",
    "  verbose=1,\n",
    "  validation_split=0.25,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoring_function(prediction):\n",
    "    arg_max = (prediction.argmax())\n",
    "    score = (prediction.argmax()+1.0)/2 - \\\n",
    "                (prediction[:arg_max].sum()*3) + \\\n",
    "                (prediction[arg_max+1:].sum()*2)\n",
    "    return round(score, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scored = pd.Series([scoring_function(x) for x in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.436830294530119"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77854137447405325"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_te_raw, scored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the weight initialization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(init_mode='uniform', optimizer = 'adam'):\n",
    "   # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(max_words,), kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(y_train[0]), kernel_initializer=init_mode, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=3, batch_size=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', \n",
    "             'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "param_grid = dict(init_mode=init_mode, optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
