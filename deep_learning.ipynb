{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "pd.options.display.float_format = '{:20,.4f}'.format\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Bring in Data\n",
    "con = sqlite3.connect(\"pitchfork-data.db\")\n",
    "review_data = pd.read_sql_query(\"SELECT * from review_text\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_data[\"score\"] = review_data[\"score\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.018776620918074"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data[\"score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>author_type</th>\n",
       "      <th>link</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A decade after their last album, Grandaddy pic...</td>\n",
       "      <td>Ian Cohen</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22950-...</td>\n",
       "      <td>Some Grandaddy songs are about technology. Nea...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The new album from New York’s Immolation is a ...</td>\n",
       "      <td>Saby Reyes-Kulkarni</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22956-...</td>\n",
       "      <td>In the early ’90s, death metal luminaries like...</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 20th anniversary remaster of Smith's final...</td>\n",
       "      <td>Matt LeMay</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22947-...</td>\n",
       "      <td>About two minutes into Either/Or opener “Speed...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yoni Wolf's prog-rap project is rejuvenated, a...</td>\n",
       "      <td>Ian Cohen</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22945-...</td>\n",
       "      <td>The end of WHY? had never been too far from Yo...</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Brazilian songwriter Erasmo Carlos remains...</td>\n",
       "      <td>Michael J. Agovino</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22908-...</td>\n",
       "      <td>Over the last half century, few countries have...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract               author  \\\n",
       "0  A decade after their last album, Grandaddy pic...            Ian Cohen   \n",
       "1  The new album from New York’s Immolation is a ...  Saby Reyes-Kulkarni   \n",
       "2  The 20th anniversary remaster of Smith's final...           Matt LeMay   \n",
       "3  Yoni Wolf's prog-rap project is rejuvenated, a...            Ian Cohen   \n",
       "4  The Brazilian songwriter Erasmo Carlos remains...   Michael J. Agovino   \n",
       "\n",
       "   author_type                                               link  \\\n",
       "0  Contributor  http://www.pitchfork.com/reviews/albums/22950-...   \n",
       "1  Contributor  http://www.pitchfork.com/reviews/albums/22956-...   \n",
       "2  Contributor  http://www.pitchfork.com/reviews/albums/22947-...   \n",
       "3  Contributor  http://www.pitchfork.com/reviews/albums/22945-...   \n",
       "4  Contributor  http://www.pitchfork.com/reviews/albums/22908-...   \n",
       "\n",
       "                                              review  score  \n",
       "0  Some Grandaddy songs are about technology. Nea...    6.0  \n",
       "1  In the early ’90s, death metal luminaries like...    7.7  \n",
       "2  About two minutes into Either/Or opener “Speed...   10.0  \n",
       "3  The end of WHY? had never been too far from Yo...    7.7  \n",
       "4  Over the last half century, few countries have...    8.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 123\n",
    "x = review_data[\"abstract\"]\n",
    "Y = np.where(review_data[\"score\"] >= 7.1, 1, 0)\n",
    "Y = review_data[\"score\"].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# only work with the 10000 most popular words found in our dataset\n",
    "max_words = 10000\n",
    "\n",
    "# create a new Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "# feed our tweets to the Tokenizer\n",
    "tokenizer.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenizers come with a convenient list of words and IDs\n",
    "dictionary = tokenizer.word_index\n",
    "# Let's save this out so we can use it later\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_index_array(text):\n",
    "    # one really important thing that `text_to_word_sequence` does\n",
    "    # is make all texts the same length -- in this case, the length\n",
    "    # of the longest text in the set.\n",
    "    return [dictionary[word] for word in kpt.text_to_word_sequence(text)]\n",
    "\n",
    "allWordIndices = []\n",
    "# for each tweet, change each token to its ID in the Tokenizer's word_index\n",
    "for text in x:\n",
    "    wordIndices = convert_text_to_index_array(text)\n",
    "    allWordIndices.append(wordIndices)\n",
    "\n",
    "# now we have a list of all tweets converted to index arrays.\n",
    "# cast as an array for future usage.\n",
    "allWordIndices = np.asarray(allWordIndices)\n",
    "\n",
    "# create one-hot matrices out of the indexed tweets\n",
    "clean_x = tokenizer.sequences_to_matrix(allWordIndices, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_x, dummy_y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12170 samples, validate on 1353 samples\n",
      "Epoch 1/5\n",
      "12170/12170 [==============================] - 18s 2ms/step - loss: 1.6255 - acc: 0.3539 - val_loss: 1.4848 - val_acc: 0.3962\n",
      "Epoch 2/5\n",
      "12170/12170 [==============================] - 19s 2ms/step - loss: 1.2967 - acc: 0.5141 - val_loss: 1.4874 - val_acc: 0.4154\n",
      "Epoch 3/5\n",
      "12170/12170 [==============================] - 19s 2ms/step - loss: 0.8513 - acc: 0.7033 - val_loss: 1.6853 - val_acc: 0.4228\n",
      "Epoch 4/5\n",
      "12170/12170 [==============================] - 19s 2ms/step - loss: 0.4359 - acc: 0.8586 - val_loss: 1.9941 - val_acc: 0.4331\n",
      "Epoch 5/5\n",
      "12170/12170 [==============================] - 19s 2ms/step - loss: 0.2151 - acc: 0.9393 - val_loss: 2.3865 - val_acc: 0.4412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b2b6590>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "  batch_size=32,\n",
    "  epochs=5,\n",
    "  verbose=1,\n",
    "  validation_split=0.1,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "score = mean_absolute_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.985, 0.014,\n",
       "       0.000, 0.000], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 1.000, 0.000,\n",
       "       0.000, 0.000])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
