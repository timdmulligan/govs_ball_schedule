{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "pd.options.display.float_format = '{:20,.4f}'.format\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in data from the web scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Bring in Data\n",
    "con = sqlite3.connect(\"pitchfork-data.db\")\n",
    "review_data = pd.read_sql_query(\"SELECT * from review_text\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.03038379530912"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data[\"score\"] = review_data[\"score\"].astype(float)\n",
    "review_data[\"score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>author_type</th>\n",
       "      <th>link</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A decade after their last album, Grandaddy pic...</td>\n",
       "      <td>Ian Cohen</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22950-...</td>\n",
       "      <td>Some Grandaddy songs are about technology. Nea...</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The new album from New York’s Immolation is a ...</td>\n",
       "      <td>Saby Reyes-Kulkarni</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22956-...</td>\n",
       "      <td>In the early ’90s, death metal luminaries like...</td>\n",
       "      <td>7.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 20th anniversary remaster of Smith's final...</td>\n",
       "      <td>Matt LeMay</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22947-...</td>\n",
       "      <td>About two minutes into Either/Or opener “Speed...</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yoni Wolf's prog-rap project is rejuvenated, a...</td>\n",
       "      <td>Ian Cohen</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22945-...</td>\n",
       "      <td>The end of WHY? had never been too far from Yo...</td>\n",
       "      <td>7.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Brazilian songwriter Erasmo Carlos remains...</td>\n",
       "      <td>Michael J. Agovino</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>http://www.pitchfork.com/reviews/albums/22908-...</td>\n",
       "      <td>Over the last half century, few countries have...</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract               author  \\\n",
       "0  A decade after their last album, Grandaddy pic...            Ian Cohen   \n",
       "1  The new album from New York’s Immolation is a ...  Saby Reyes-Kulkarni   \n",
       "2  The 20th anniversary remaster of Smith's final...           Matt LeMay   \n",
       "3  Yoni Wolf's prog-rap project is rejuvenated, a...            Ian Cohen   \n",
       "4  The Brazilian songwriter Erasmo Carlos remains...   Michael J. Agovino   \n",
       "\n",
       "   author_type                                               link  \\\n",
       "0  Contributor  http://www.pitchfork.com/reviews/albums/22950-...   \n",
       "1  Contributor  http://www.pitchfork.com/reviews/albums/22956-...   \n",
       "2  Contributor  http://www.pitchfork.com/reviews/albums/22947-...   \n",
       "3  Contributor  http://www.pitchfork.com/reviews/albums/22945-...   \n",
       "4  Contributor  http://www.pitchfork.com/reviews/albums/22908-...   \n",
       "\n",
       "                                              review                score  \n",
       "0  Some Grandaddy songs are about technology. Nea...               6.0000  \n",
       "1  In the early ’90s, death metal luminaries like...               7.7000  \n",
       "2  About two minutes into Either/Or opener “Speed...              10.0000  \n",
       "3  The end of WHY? had never been too far from Yo...               7.7000  \n",
       "4  Over the last half century, few countries have...               8.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into X and Y and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = review_data[\"review\"]\n",
    "Y = review_data[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# only work with the n most popular words found in our dataset\n",
    "max_words = 5000\n",
    "\n",
    "# create a new Tokenizer and feed reviews to it\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenizers come with a convenient list of words and IDs\n",
    "# Save it so we can reference it later\n",
    "dictionary = tokenizer.word_index\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.preprocessing.text as kpt\n",
    "\n",
    "def convert_text_to_index_array(text):\n",
    "    # one really important thing that `text_to_word_sequence` does\n",
    "    # is make all texts the same length -- in this case, the length\n",
    "    # of the longest text in the set.\n",
    "    return [dictionary[word] for word in kpt.text_to_word_sequence(text)]\n",
    "\n",
    "# for each review, change each token to its ID in the Tokenizer's word_index \n",
    "allWordIndices = []\n",
    "for text in x:\n",
    "    wordIndices = convert_text_to_index_array(text)\n",
    "    allWordIndices.append(wordIndices)\n",
    "\n",
    "# now we have a list of all tweets converted to index arrays.\n",
    "# cast as an array for future usage.\n",
    "allWordIndices = np.asarray(allWordIndices)\n",
    "\n",
    "# create one-hot matrices out of the indexed tweets\n",
    "clean_x = tokenizer.sequences_to_matrix(allWordIndices, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 123\n",
    "X_train, X_test, y_tr_raw, y_te_raw = train_test_split(clean_x, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10692 samples, validate on 3565 samples\n",
      "Epoch 1/5\n",
      "10692/10692 [==============================] - 12s 1ms/step - loss: 1.0989 - mean_absolute_error: 1.0989 - val_loss: 0.7882 - val_mean_absolute_error: 0.7882\n",
      "Epoch 2/5\n",
      "10692/10692 [==============================] - 10s 975us/step - loss: 0.7395 - mean_absolute_error: 0.7395 - val_loss: 0.8111 - val_mean_absolute_error: 0.8111\n",
      "Epoch 3/5\n",
      "10692/10692 [==============================] - 10s 902us/step - loss: 0.6750 - mean_absolute_error: 0.6750 - val_loss: 0.7955 - val_mean_absolute_error: 0.7955\n",
      "Epoch 4/5\n",
      "10692/10692 [==============================] - 10s 919us/step - loss: 0.6238 - mean_absolute_error: 0.6238 - val_loss: 0.8541 - val_mean_absolute_error: 0.8541\n",
      "Epoch 5/5\n",
      "10692/10692 [==============================] - 10s 928us/step - loss: 0.6152 - mean_absolute_error: 0.6152 - val_loss: 0.7636 - val_mean_absolute_error: 0.7636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13579ad50>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def regression_model(activation, kernal):\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(512, activation=activation, kernel_initializer=kernal, input_shape=(max_words,)))\n",
    "    regressor.add(Dense(256, activation=activation, kernel_initializer=kernal))\n",
    "    regressor.add(Dense(12, activation=activation, kernel_initializer=kernal))\n",
    "    regressor.add(Dense(1, activation=activation, kernel_initializer=kernal))\n",
    "    regressor.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])\n",
    "    return regressor\n",
    "\n",
    "regression_model(\"linear\", \"uniform\").fit(X_train, y_tr_raw,\n",
    "  batch_size=32,\n",
    "  epochs=5,\n",
    "  verbose=1,\n",
    "  validation_split=0.25,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scored = regression_model(\"linear\", \"uniform\").predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.034],\n",
       "       [-0.001],\n",
       "       [0.017],\n",
       "       ..., \n",
       "       [0.011],\n",
       "       [0.001],\n",
       "       [0.007]], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0295280350707232"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_te_raw, scored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def myround(x, prec=1, base=.5):\n",
    "    return round(base * round(float(x)/base),prec)\n",
    "\n",
    "#Convert to multi-class dummy variables \n",
    "y_tr, y_te = [myround(x) for x in pd.Series(y_tr_raw)],[myround(x) for x in y_te_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(pd.get_dummies(y_tr))\n",
    "y_test = np.array(pd.get_dummies(y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[0]), len(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, kernel_initializer='glorot_normal', input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, kernel_initializer='glorot_normal', activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(y_train[0]), kernel_initializer='glorot_normal', activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10692 samples, validate on 3565 samples\n",
      "Epoch 1/10\n",
      "10692/10692 [==============================] - 9s 796us/step - loss: 0.3706 - acc: 0.8805 - val_loss: 2.5184 - val_acc: 0.3784\n",
      "Epoch 2/10\n",
      "10692/10692 [==============================] - 9s 809us/step - loss: 0.3055 - acc: 0.9020 - val_loss: 2.5932 - val_acc: 0.3829\n",
      "Epoch 3/10\n",
      "10692/10692 [==============================] - 9s 825us/step - loss: 0.2794 - acc: 0.9105 - val_loss: 2.6959 - val_acc: 0.3902\n",
      "Epoch 4/10\n",
      "10692/10692 [==============================] - 9s 840us/step - loss: 0.2466 - acc: 0.9209 - val_loss: 2.7002 - val_acc: 0.3759\n",
      "Epoch 5/10\n",
      "10692/10692 [==============================] - 9s 815us/step - loss: 0.2268 - acc: 0.9285 - val_loss: 2.7076 - val_acc: 0.3762\n",
      "Epoch 6/10\n",
      "10692/10692 [==============================] - 9s 829us/step - loss: 0.2106 - acc: 0.9332 - val_loss: 3.0078 - val_acc: 0.3792\n",
      "Epoch 7/10\n",
      "10692/10692 [==============================] - 9s 825us/step - loss: 0.2068 - acc: 0.9313 - val_loss: 2.8789 - val_acc: 0.3795\n",
      "Epoch 8/10\n",
      "10692/10692 [==============================] - 9s 829us/step - loss: 0.1838 - acc: 0.9425 - val_loss: 2.9296 - val_acc: 0.3837\n",
      "Epoch 9/10\n",
      "10692/10692 [==============================] - 9s 826us/step - loss: 0.1836 - acc: 0.9400 - val_loss: 3.1008 - val_acc: 0.3798\n",
      "Epoch 10/10\n",
      "10692/10692 [==============================] - 9s 851us/step - loss: 0.1663 - acc: 0.9473 - val_loss: 3.1758 - val_acc: 0.3753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18dc4ad50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "  batch_size=32,\n",
    "  epochs=10,\n",
    "  verbose=1,\n",
    "  validation_split=0.25,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoring_function(prediction):\n",
    "    arg_max = (prediction.argmax())\n",
    "    score = (prediction.argmax()+1.0)/2 - \\\n",
    "                (prediction[:arg_max].sum()*3) + \\\n",
    "                (prediction[arg_max+1:].sum()*2)\n",
    "    return round(score, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scored = pd.Series([scoring_function(x) for x in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4592426367461435"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79618513323983164"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_te_raw, scored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the weight initialization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(init_mode='uniform', optimizer = 'adam'):\n",
    "   # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(max_words,), kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(y_train[0]), kernel_initializer=init_mode, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=3, batch_size=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', \n",
    "             'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "param_grid = dict(init_mode=init_mode, optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 27s - loss: 2.2673 - acc: 0.2009\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      " - 32s - loss: 2.2619 - acc: 0.1948\n",
      "Epoch 2/3\n",
      " - 39s - loss: 2.2642 - acc: 0.2031\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 52s - loss: 2.2388 - acc: 0.2042\n",
      "Epoch 3/3\n",
      " - 56s - loss: 2.2312 - acc: 0.2019\n",
      "Epoch 3/3\n",
      " - 60s - loss: 2.2329 - acc: 0.1976\n",
      "Epoch 3/3\n",
      " - 98s - loss: 2.1473 - acc: 0.2319\n",
      "Epoch 2/3\n",
      " - 109s - loss: 2.1529 - acc: 0.2270\n",
      "Epoch 2/3\n",
      " - 66s - loss: 2.2323 - acc: 0.1977\n",
      " - 116s - loss: 2.1442 - acc: 0.2397\n",
      "Epoch 2/3\n",
      " - 65s - loss: 2.2286 - acc: 0.2059\n",
      " - 110s - loss: 2.1347 - acc: 0.2301\n",
      "Epoch 2/3\n",
      " - 63s - loss: 2.2323 - acc: 0.2076\n",
      " - 111s - loss: 2.1484 - acc: 0.2263\n",
      "Epoch 2/3\n",
      " - 93s - loss: 1.9179 - acc: 0.3198\n",
      "Epoch 3/3\n",
      " - 85s - loss: 1.9431 - acc: 0.3131\n",
      "Epoch 3/3\n",
      " - 69s - loss: 1.7751 - acc: 0.3527\n",
      "Epoch 3/3\n",
      " - 78s - loss: 1.9081 - acc: 0.3292\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 65s - loss: 1.7681 - acc: 0.3590\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 82s - loss: 1.7586 - acc: 0.3899\n",
      " - 89s - loss: 1.7913 - acc: 0.3780\n",
      " - 80s - loss: 1.4979 - acc: 0.4786\n",
      " - 91s - loss: 1.7255 - acc: 0.4084\n",
      " - 92s - loss: 2.1220 - acc: 0.2424\n",
      "Epoch 2/3\n",
      " - 85s - loss: 1.4793 - acc: 0.4843\n",
      "Epoch 1/3\n",
      " - 122s - loss: 2.1690 - acc: 0.2294\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      " - 48s - loss: 1.7546 - acc: 0.3660\n",
      "Epoch 3/3\n",
      " - 119s - loss: 2.1767 - acc: 0.2202\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 85s - loss: 1.4750 - acc: 0.4844\n",
      " - 131s - loss: 2.0996 - acc: 0.2433\n",
      "Epoch 2/3\n",
      " - 138s - loss: 1.9000 - acc: 0.3061\n",
      "Epoch 3/3\n",
      " - 137s - loss: 2.1033 - acc: 0.2360\n",
      "Epoch 2/3\n",
      " - 152s - loss: 2.1691 - acc: 0.2274\n",
      "Epoch 2/3\n",
      " - 150s - loss: 1.9176 - acc: 0.2915\n",
      "Epoch 3/3\n",
      " - 133s - loss: 2.1684 - acc: 0.2312\n",
      "Epoch 2/3\n",
      " - 146s - loss: 2.1125 - acc: 0.2419\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      " - 132s - loss: 1.7115 - acc: 0.3753\n",
      "Epoch 3/3\n",
      " - 131s - loss: 1.7166 - acc: 0.3624\n",
      "Epoch 3/3\n",
      " - 124s - loss: 1.8672 - acc: 0.3232\n",
      "Epoch 3/3\n",
      " - 163s - loss: 1.6751 - acc: 0.3860\n",
      " - 137s - loss: 1.7331 - acc: 0.3597\n",
      "Epoch 3/3\n",
      " - 164s - loss: 1.9036 - acc: 0.3027\n",
      "Epoch 3/3\n",
      " - 165s - loss: 1.6940 - acc: 0.3805\n",
      " - 140s - loss: 2.1681 - acc: 0.2283\n",
      "Epoch 2/3\n",
      " - 121s - loss: 1.2408 - acc: 0.5683\n",
      "Epoch 1/3\n",
      " - 104s - loss: 1.5901 - acc: 0.4396\n",
      " - 116s - loss: 1.2377 - acc: 0.5717\n",
      " - 106s - loss: 1.2980 - acc: 0.5371\n",
      " - 88s - loss: 1.8679 - acc: 0.3219\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 116s - loss: 1.6888 - acc: 0.3772\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 79s - loss: 2.1682 - acc: 0.2279\n",
      "Epoch 2/3\n",
      " - 63s - loss: 1.5836 - acc: 0.4361\n",
      "Epoch 1/3\n",
      " - 58s - loss: 2.3209 - acc: 0.1969\n",
      "Epoch 2/3\n",
      " - 71s - loss: 2.3138 - acc: 0.1942\n",
      "Epoch 2/3\n",
      " - 117s - loss: 2.1085 - acc: 0.2311\n",
      "Epoch 2/3\n",
      " - 81s - loss: 2.3215 - acc: 0.1942\n",
      "Epoch 2/3\n",
      " - 56s - loss: 2.2555 - acc: 0.2081\n",
      "Epoch 3/3\n",
      " - 100s - loss: 1.8667 - acc: 0.3259\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 55s - loss: 2.2508 - acc: 0.2029\n",
      "Epoch 3/3\n",
      " - 143s - loss: 2.1381 - acc: 0.2305\n",
      "Epoch 2/3\n",
      " - 153s - loss: 2.1299 - acc: 0.2329\n",
      "Epoch 2/3\n",
      " - 58s - loss: 2.2546 - acc: 0.2033\n",
      "Epoch 3/3\n",
      " - 59s - loss: 2.2256 - acc: 0.2043\n",
      " - 60s - loss: 2.2185 - acc: 0.2100\n",
      " - 55s - loss: 2.2267 - acc: 0.2044\n",
      " - 106s - loss: 1.5988 - acc: 0.4279\n",
      " - 147s - loss: 1.7575 - acc: 0.3486\n",
      "Epoch 3/3\n",
      " - 108s - loss: 2.1729 - acc: 0.2312\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 127s - loss: 1.7834 - acc: 0.3316\n",
      "Epoch 3/3\n",
      " - 123s - loss: 1.7634 - acc: 0.3460\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 74s - loss: 1.9258 - acc: 0.3166\n",
      "Epoch 3/3\n",
      " - 96s - loss: 2.1740 - acc: 0.2282\n",
      "Epoch 2/3\n",
      " - 126s - loss: 1.3336 - acc: 0.5255\n",
      " - 101s - loss: 2.1679 - acc: 0.2270\n",
      "Epoch 2/3\n",
      " - 98s - loss: 2.1873 - acc: 0.2220\n",
      "Epoch 2/3\n",
      " - 100s - loss: 2.1903 - acc: 0.2140\n",
      "Epoch 2/3\n",
      " - 97s - loss: 1.7479 - acc: 0.4067\n",
      " - 143s - loss: 1.3719 - acc: 0.5044\n",
      " - 142s - loss: 1.3817 - acc: 0.5010\n",
      " - 85s - loss: 1.9039 - acc: 0.3252\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 81s - loss: 1.9055 - acc: 0.3225\n",
      "Epoch 3/3\n",
      " - 66s - loss: 1.8050 - acc: 0.3529\n",
      "Epoch 3/3\n",
      " - 63s - loss: 1.8477 - acc: 0.3344\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 67s - loss: 1.7190 - acc: 0.4062\n",
      " - 70s - loss: 2.1938 - acc: 0.2226\n",
      "Epoch 2/3\n",
      " - 70s - loss: 1.7245 - acc: 0.4075\n",
      " - 64s - loss: 1.5287 - acc: 0.4642\n",
      " - 67s - loss: 1.5717 - acc: 0.4547\n",
      " - 59s - loss: 1.8176 - acc: 0.3472\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 111s - loss: 2.2094 - acc: 0.2154\n",
      "Epoch 2/3\n",
      " - 111s - loss: 2.1913 - acc: 0.2137\n",
      "Epoch 2/3\n",
      " - 118s - loss: 2.1873 - acc: 0.2157\n",
      "Epoch 2/3\n",
      " - 77s - loss: 1.5336 - acc: 0.4752\n",
      " - 129s - loss: 2.1506 - acc: 0.2259\n",
      "Epoch 2/3\n",
      " - 134s - loss: 2.1651 - acc: 0.2251\n",
      "Epoch 2/3\n",
      " - 136s - loss: 2.2316 - acc: 0.2153\n",
      "Epoch 2/3\n",
      " - 146s - loss: 2.1490 - acc: 0.2355\n",
      "Epoch 2/3\n",
      " - 149s - loss: 1.8954 - acc: 0.3105\n",
      "Epoch 3/3\n",
      " - 151s - loss: 1.8998 - acc: 0.2967\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 152s - loss: 1.8857 - acc: 0.3046\n",
      "Epoch 3/3\n",
      " - 130s - loss: 1.7366 - acc: 0.3674\n",
      "Epoch 3/3\n",
      " - 115s - loss: 1.9047 - acc: 0.3219\n",
      "Epoch 3/3\n",
      " - 132s - loss: 1.7527 - acc: 0.3587\n",
      "Epoch 3/3\n",
      " - 133s - loss: 1.7527 - acc: 0.3607\n",
      "Epoch 3/3\n",
      " - 140s - loss: 2.2230 - acc: 0.2095\n",
      "Epoch 2/3\n",
      " - 164s - loss: 1.6693 - acc: 0.3980\n",
      " - 164s - loss: 1.6877 - acc: 0.3862\n",
      " - 163s - loss: 1.6696 - acc: 0.3954\n",
      " - 110s - loss: 1.6272 - acc: 0.4287\n",
      " - 121s - loss: 1.2918 - acc: 0.5491\n",
      " - 115s - loss: 1.3392 - acc: 0.5325\n",
      " - 106s - loss: 1.3218 - acc: 0.5320\n",
      "Epoch 1/3\n",
      " - 77s - loss: 1.9072 - acc: 0.3128\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 76s - loss: 1.6205 - acc: 0.4202\n",
      " - 64s - loss: 2.3042 - acc: 0.1962\n",
      "Epoch 2/3\n",
      " - 86s - loss: 2.2081 - acc: 0.2135\n",
      "Epoch 2/3\n",
      " - 71s - loss: 2.3006 - acc: 0.2015\n",
      "Epoch 2/3\n",
      " - 75s - loss: 2.3035 - acc: 0.1993\n",
      "Epoch 2/3\n",
      " - 57s - loss: 2.2442 - acc: 0.2028\n",
      "Epoch 3/3\n",
      " - 141s - loss: 2.1513 - acc: 0.2326\n",
      "Epoch 2/3\n",
      " - 56s - loss: 2.2369 - acc: 0.2029\n",
      "Epoch 3/3\n",
      " - 150s - loss: 2.1586 - acc: 0.2265\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      " - 56s - loss: 2.2408 - acc: 0.2087\n",
      "Epoch 3/3\n",
      " - 158s - loss: 2.1295 - acc: 0.2315\n",
      "Epoch 2/3\n",
      " - 104s - loss: 1.8973 - acc: 0.3190\n",
      "Epoch 3/3\n",
      " - 57s - loss: 2.2240 - acc: 0.2042\n",
      " - 58s - loss: 2.2149 - acc: 0.2109\n",
      " - 57s - loss: 2.2176 - acc: 0.2138\n",
      " - 101s - loss: 2.1859 - acc: 0.2229\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      " - 89s - loss: 1.6163 - acc: 0.4265\n",
      " - 132s - loss: 1.7846 - acc: 0.3422\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 128s - loss: 1.7769 - acc: 0.3479\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 124s - loss: 1.7723 - acc: 0.3427\n",
      "Epoch 3/3\n",
      " - 83s - loss: 1.9550 - acc: 0.3098\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 106s - loss: 2.1967 - acc: 0.2228\n",
      "Epoch 2/3\n",
      " - 99s - loss: 2.1912 - acc: 0.2193\n",
      "Epoch 2/3\n",
      " - 95s - loss: 2.2045 - acc: 0.2279\n",
      "Epoch 2/3\n",
      " - 138s - loss: 1.4372 - acc: 0.4854\n",
      " - 143s - loss: 1.4021 - acc: 0.5136\n",
      " - 142s - loss: 1.3925 - acc: 0.4965\n",
      " - 95s - loss: 1.8138 - acc: 0.3893\n",
      " - 105s - loss: 2.1931 - acc: 0.2214\n",
      "Epoch 2/3\n",
      " - 78s - loss: 1.8549 - acc: 0.3327\n",
      "Epoch 3/3\n",
      " - 87s - loss: 1.9838 - acc: 0.3006\n",
      "Epoch 3/3\n",
      " - 86s - loss: 1.9824 - acc: 0.2999\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 55s - loss: 1.8287 - acc: 0.3392\n",
      "Epoch 3/3\n",
      " - 55s - loss: 1.5301 - acc: 0.4661\n",
      " - 64s - loss: 1.8193 - acc: 0.3796\n",
      " - 64s - loss: 1.8239 - acc: 0.3781\n",
      " - 72s - loss: 2.2042 - acc: 0.2182\n",
      "Epoch 2/3\n",
      " - 66s - loss: 1.5257 - acc: 0.4651\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 116s - loss: 2.2134 - acc: 0.2152\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      " - 58s - loss: 1.8455 - acc: 0.3466\n",
      "Epoch 3/3\n",
      " - 129s - loss: 2.2147 - acc: 0.2200\n",
      "Epoch 2/3\n",
      " - 132s - loss: 2.2056 - acc: 0.2243\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      " - 87s - loss: 1.5080 - acc: 0.4812\n",
      " - 131s - loss: 2.1697 - acc: 0.2284\n",
      "Epoch 2/3\n",
      " - 132s - loss: 2.1696 - acc: 0.2190\n",
      "Epoch 2/3\n",
      " - 145s - loss: 1.9370 - acc: 0.2928\n",
      "Epoch 3/3\n",
      " - 140s - loss: 2.1604 - acc: 0.2285\n",
      "Epoch 2/3\n",
      " - 150s - loss: 1.9304 - acc: 0.2979\n",
      "Epoch 3/3\n",
      " - 129s - loss: 2.2216 - acc: 0.2146\n",
      "Epoch 2/3\n",
      " - 149s - loss: 1.9266 - acc: 0.2994\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 125s - loss: 1.7567 - acc: 0.3633\n",
      "Epoch 3/3\n",
      " - 126s - loss: 1.7574 - acc: 0.3607\n",
      "Epoch 3/3\n",
      " - 132s - loss: 1.7530 - acc: 0.3685\n",
      "Epoch 3/3\n",
      " - 117s - loss: 1.9461 - acc: 0.3056\n",
      "Epoch 3/3\n",
      " - 158s - loss: 1.6908 - acc: 0.3936\n",
      " - 158s - loss: 1.6982 - acc: 0.3816\n",
      " - 158s - loss: 1.6900 - acc: 0.3898\n",
      " - 139s - loss: 2.2184 - acc: 0.2185\n",
      "Epoch 2/3\n",
      " - 125s - loss: 1.2396 - acc: 0.5710\n",
      " - 123s - loss: 1.2334 - acc: 0.5730\n",
      " - 108s - loss: 1.2613 - acc: 0.5668\n",
      " - 87s - loss: 1.6572 - acc: 0.4127\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 61s - loss: 1.9402 - acc: 0.3074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 85s - loss: 2.2228 - acc: 0.2156\n",
      "Epoch 2/3\n",
      " - 73s - loss: 2.2510 - acc: 0.2036\n",
      "Epoch 2/3\n",
      " - 98s - loss: 1.6661 - acc: 0.4109\n",
      " - 81s - loss: 2.2417 - acc: 0.2067\n",
      "Epoch 2/3\n",
      " - 83s - loss: 2.2451 - acc: 0.2102\n",
      "Epoch 2/3\n",
      " - 143s - loss: 2.1811 - acc: 0.2272\n",
      "Epoch 2/3\n",
      " - 148s - loss: 2.2150 - acc: 0.2048\n",
      "Epoch 2/3\n",
      " - 64s - loss: 2.2309 - acc: 0.2000\n",
      "Epoch 3/3\n",
      " - 62s - loss: 2.2249 - acc: 0.2059\n",
      "Epoch 3/3\n",
      " - 160s - loss: 2.1737 - acc: 0.2204\n",
      "Epoch 2/3\n",
      " - 107s - loss: 1.9450 - acc: 0.3102\n",
      "Epoch 3/3\n",
      " - 61s - loss: 2.2292 - acc: 0.2058\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 62s - loss: 2.2296 - acc: 0.1999\n",
      " - 63s - loss: 2.2255 - acc: 0.2050\n",
      " - 62s - loss: 2.2280 - acc: 0.2101\n",
      " - 95s - loss: 1.6634 - acc: 0.4073\n",
      " - 140s - loss: 1.8360 - acc: 0.3208\n",
      "Epoch 3/3\n",
      " - 135s - loss: 1.8998 - acc: 0.2885\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      " - 97s - loss: 2.2918 - acc: 0.2098\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      " - 124s - loss: 1.8289 - acc: 0.3231\n",
      "Epoch 3/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      " - 82s - loss: 2.3014 - acc: 0.2027\n",
      "Epoch 3/3\n",
      " - 97s - loss: 2.2883 - acc: 0.2084\n",
      "Epoch 2/3\n",
      " - 126s - loss: 1.4486 - acc: 0.4779\n",
      " - 128s - loss: 1.5630 - acc: 0.4255\n",
      " - 107s - loss: 2.2311 - acc: 0.2072\n",
      "Epoch 2/3\n",
      " - 115s - loss: 2.2925 - acc: 0.2067\n",
      "Epoch 2/3\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.362909 using {'init_mode': 'glorot_normal', 'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.206986 (0.022439) with: {'init_mode': 'uniform', 'optimizer': 'SGD'}\n",
      "0.306446 (0.013955) with: {'init_mode': 'uniform', 'optimizer': 'RMSprop'}\n",
      "0.333731 (0.008312) with: {'init_mode': 'uniform', 'optimizer': 'Adagrad'}\n",
      "0.309743 (0.008006) with: {'init_mode': 'uniform', 'optimizer': 'Adadelta'}\n",
      "0.355825 (0.009553) with: {'init_mode': 'uniform', 'optimizer': 'Adam'}\n",
      "0.329382 (0.006198) with: {'init_mode': 'uniform', 'optimizer': 'Adamax'}\n",
      "0.337869 (0.008821) with: {'init_mode': 'uniform', 'optimizer': 'Nadam'}\n",
      "0.203128 (0.017587) with: {'init_mode': 'lecun_uniform', 'optimizer': 'SGD'}\n",
      "0.314091 (0.006023) with: {'init_mode': 'lecun_uniform', 'optimizer': 'RMSprop'}\n",
      "0.330294 (0.004184) with: {'init_mode': 'lecun_uniform', 'optimizer': 'Adagrad'}\n",
      "0.308129 (0.013032) with: {'init_mode': 'lecun_uniform', 'optimizer': 'Adadelta'}\n",
      "0.355685 (0.009150) with: {'init_mode': 'lecun_uniform', 'optimizer': 'Adam'}\n",
      "0.323701 (0.003333) with: {'init_mode': 'lecun_uniform', 'optimizer': 'Adamax'}\n",
      "0.354282 (0.011311) with: {'init_mode': 'lecun_uniform', 'optimizer': 'Nadam'}\n",
      "0.226064 (0.005918) with: {'init_mode': 'normal', 'optimizer': 'SGD'}\n",
      "0.300905 (0.005681) with: {'init_mode': 'normal', 'optimizer': 'RMSprop'}\n",
      "0.338571 (0.005433) with: {'init_mode': 'normal', 'optimizer': 'Adagrad'}\n",
      "0.306586 (0.002470) with: {'init_mode': 'normal', 'optimizer': 'Adadelta'}\n",
      "0.360314 (0.008115) with: {'init_mode': 'normal', 'optimizer': 'Adam'}\n",
      "0.331136 (0.011098) with: {'init_mode': 'normal', 'optimizer': 'Adamax'}\n",
      "0.328400 (0.014186) with: {'init_mode': 'normal', 'optimizer': 'Nadam'}\n",
      "0.203830 (0.024903) with: {'init_mode': 'zero', 'optimizer': 'SGD'}\n",
      "0.221365 (0.002386) with: {'init_mode': 'zero', 'optimizer': 'RMSprop'}\n",
      "0.221365 (0.002386) with: {'init_mode': 'zero', 'optimizer': 'Adagrad'}\n",
      "0.221365 (0.002386) with: {'init_mode': 'zero', 'optimizer': 'Adadelta'}\n",
      "0.221365 (0.002386) with: {'init_mode': 'zero', 'optimizer': 'Adam'}\n",
      "0.221365 (0.002386) with: {'init_mode': 'zero', 'optimizer': 'Adamax'}\n",
      "0.203409 (0.023361) with: {'init_mode': 'zero', 'optimizer': 'Nadam'}\n",
      "0.222768 (0.006013) with: {'init_mode': 'glorot_normal', 'optimizer': 'SGD'}\n",
      "0.307358 (0.004865) with: {'init_mode': 'glorot_normal', 'optimizer': 'RMSprop'}\n",
      "0.332819 (0.006847) with: {'init_mode': 'glorot_normal', 'optimizer': 'Adagrad'}\n",
      "0.316196 (0.005077) with: {'init_mode': 'glorot_normal', 'optimizer': 'Adadelta'}\n",
      "0.358982 (0.006734) with: {'init_mode': 'glorot_normal', 'optimizer': 'Adam'}\n",
      "0.320685 (0.001310) with: {'init_mode': 'glorot_normal', 'optimizer': 'Adamax'}\n",
      "0.362909 (0.011779) with: {'init_mode': 'glorot_normal', 'optimizer': 'Nadam'}\n",
      "0.221014 (0.017224) with: {'init_mode': 'glorot_uniform', 'optimizer': 'SGD'}\n",
      "0.315003 (0.005334) with: {'init_mode': 'glorot_uniform', 'optimizer': 'RMSprop'}\n",
      "0.339623 (0.007520) with: {'init_mode': 'glorot_uniform', 'optimizer': 'Adagrad'}\n",
      "0.314091 (0.001806) with: {'init_mode': 'glorot_uniform', 'optimizer': 'Adadelta'}\n",
      "0.356316 (0.005420) with: {'init_mode': 'glorot_uniform', 'optimizer': 'Adam'}\n",
      "0.321737 (0.004305) with: {'init_mode': 'glorot_uniform', 'optimizer': 'Adamax'}\n",
      "0.348040 (0.012528) with: {'init_mode': 'glorot_uniform', 'optimizer': 'Nadam'}\n",
      "0.223539 (0.019311) with: {'init_mode': 'he_normal', 'optimizer': 'SGD'}\n",
      "0.311847 (0.002653) with: {'init_mode': 'he_normal', 'optimizer': 'RMSprop'}\n",
      "0.335695 (0.008204) with: {'init_mode': 'he_normal', 'optimizer': 'Adagrad'}\n",
      "0.321526 (0.003482) with: {'init_mode': 'he_normal', 'optimizer': 'Adadelta'}\n",
      "0.356877 (0.006169) with: {'init_mode': 'he_normal', 'optimizer': 'Adam'}\n",
      "0.327769 (0.002150) with: {'init_mode': 'he_normal', 'optimizer': 'Adamax'}\n",
      "0.355334 (0.006936) with: {'init_mode': 'he_normal', 'optimizer': 'Nadam'}\n",
      "0.233499 (0.012453) with: {'init_mode': 'he_uniform', 'optimizer': 'SGD'}\n",
      "0.304833 (0.004085) with: {'init_mode': 'he_uniform', 'optimizer': 'RMSprop'}\n",
      "0.336045 (0.008445) with: {'init_mode': 'he_uniform', 'optimizer': 'Adagrad'}\n",
      "0.318721 (0.004309) with: {'init_mode': 'he_uniform', 'optimizer': 'Adadelta'}\n",
      "0.353230 (0.014220) with: {'init_mode': 'he_uniform', 'optimizer': 'Adam'}\n",
      "0.323981 (0.005171) with: {'init_mode': 'he_uniform', 'optimizer': 'Adamax'}\n",
      "0.347689 (0.005292) with: {'init_mode': 'he_uniform', 'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
